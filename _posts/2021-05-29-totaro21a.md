---
title: Fast Stochastic Kalman Gradient Descent for Reinforcement Learning
abstract: " As we move towards real world applications, there is an increasing need
  for scalable, online optimization algorithms capable of dealing with the non-stationarity
  of the real world. We revisit the problem of online policy evaluation in non-stationary
  deterministic MDPs through the lense of Kalman filtering. We introduce a randomized
  regularization technique called Stochastic Kalman Gradient Descent (SKGD) that,
  combined with a low rank update, generates a sequence of feasible iterates. SKGD
  is suitable for large scale optimization of non-linear function approximators. We
  evaluate the performance of SKGD in two controlled experiments, and in one real
  world application of microgrid control. In our experiments, SKGD is more robust
  to drift in the transition dynamics than state-of-the-art reinforcement learning
  algorithms, and the resulting policies are smoother."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: totaro21a
month: 0
tex_title: Fast Stochastic Kalman Gradient Descent for Reinforcement Learning
firstpage: 1118
lastpage: 1129
page: 1118-1129
order: 1118
cycles: false
bibtex_author: Totaro, Simone and Jonsson, Anders
author:
- given: Simone
  family: Totaro
- given: Anders
  family: Jonsson
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/totaro21a/totaro21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
