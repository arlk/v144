---
title: Improved Analysis for Dynamic Regret of Strongly Convex and Smooth Functions
abstract: In this paper, we present an improved analysis for dynamic regret of strongly
  convex and smooth functions. Specifically, we investigate the Online Multiple Gradient
  Descent (OMGD) algorithm proposed by Zhang et al. (2017). The original analysis
  shows that the dynamic regret of OMGD is at most O(min{P_T,S_T}), where P_T and
  S_T are path-length and squared path-length that measures the cumulative movement
  of minimizers of the online functions. We demonstrate that by an improved analysis,
  the dynamic regret of OMGD can be improved to O(min{P_T,S_T,V_T}), where V_T is
  the function variation of the online functions. Note that the quantities of P_T,
  S_T, V_T essentially reflect different aspects of environmental non-stationarityâ€”they
  are not comparable in general and are favored in different scenarios. Therefore,
  the dynamic regret presented in this paper actually achieves a \emph{best-of-three-worlds}
  guarantee, and is strictly tighter than previous results.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao21a
month: 0
tex_title: Improved Analysis for Dynamic Regret of Strongly Convex and Smooth Functions
firstpage: 48
lastpage: 59
page: 48-59
order: 48
cycles: false
bibtex_author: Zhao, Peng and Zhang, Lijun
author:
- given: Peng
  family: Zhao
- given: Lijun
  family: Zhang
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/zhao21a/zhao21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
