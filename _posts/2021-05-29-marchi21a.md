---
title: Training deep residual networks for uniform approximation guarantees
abstract: It has recently been shown that deep residual networks with sufficiently
  high depth, but bounded width, are capable of universal approximation in the supremum
  norm sense. Based on these results, we show how to modify existing training algorithms
  for deep residual networks so as to provide approximation bounds for the test error,
  in the supremum norm, based on the training error. Our methods are based on control-theoretic
  interpretations of these networks both in discrete and continuous time, and establish
  that it is enough to suitably constrain the set of parameters being learned in a
  way that is compatible with most currently used training algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: marchi21a
month: 0
tex_title: Training deep residual networks for uniform approximation guarantees
firstpage: 677
lastpage: 688
page: 677-688
order: 677
cycles: false
bibtex_author: Marchi, Matteo and Gharesifard, Bahman and Tabuada, Paulo
author:
- given: Matteo
  family: Marchi
- given: Bahman
  family: Gharesifard
- given: Paulo
  family: Tabuada
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/marchi21a/marchi21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
