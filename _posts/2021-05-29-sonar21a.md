---
title: 'Invariant Policy Optimization: Towards Stronger Generalization in Reinforcement
  Learning'
abstract: 'A fundamental challenge in reinforcement learning is to learn policies
  that generalize beyond the operating domains experienced during training. In this
  paper, we approach this challenge through the following invariance principle: an
  agent must find a representation such that there exists an action-predictor built
  on top of this representation that is simultaneously optimal across all training
  domains. Intuitively, the resulting invariant policy enhances generalization by
  finding causes of successful actions. We propose a novel learning algorithm, Invariant
  Policy Optimization (IPO), that implements this principle and learns an invariant
  policy during training. We compare our approach with standard policy gradient methods
  and demonstrate significant improvements in generalization performance on unseen
  domains for linear quadratic regulator and grid-world problems, and an example where
  a robot must learn to open doors with varying physical properties. '
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sonar21a
month: 0
tex_title: 'Invariant Policy Optimization: Towards Stronger Generalization in Reinforcement
  Learning'
firstpage: 21
lastpage: 33
page: 21-33
order: 21
cycles: false
bibtex_author: Sonar, Anoopkumar and Pacelli, Vincent and Majumdar, Anirudha
author:
- given: Anoopkumar
  family: Sonar
- given: Vincent
  family: Pacelli
- given: Anirudha
  family: Majumdar
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/sonar21a/sonar21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
