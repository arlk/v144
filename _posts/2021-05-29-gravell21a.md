---
title: Approximate Midpoint Policy Iteration for Linear Quadratic Control
abstract: We present a midpoint policy iteration algorithm to solve linear quadratic
  optimal control problems in both model-based and model-free settings. The algorithm
  is a variation of Newtonâ€™s method, and we show that in the model-based setting it
  achieves cubic convergence, which is superior to standard policy iteration and policy
  gradient algorithms that achieve quadratic and linear convergence, respectively.
  We also demonstrate that the algorithm can be approximately implemented without
  knowledge of the dynamics model by using least-squares estimates of the state-action
  value function from trajectory data, from which policy improvements can be obtained.
  With sufficient trajectory data, the policy iterates converge cubically to approximately
  optimal policies, and this occurs with  the  same  available  sample  budget  as  the  approximate
  standard policy iteration. Numerical experiments demonstrate effectiveness of the
  proposed algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gravell21a
month: 0
tex_title: Approximate Midpoint Policy Iteration for Linear Quadratic Control
firstpage: 1080
lastpage: 1092
page: 1080-1092
order: 1080
cycles: false
bibtex_author: Gravell, Benjamin and Shames, Iman and Summers, Tyler
author:
- given: Benjamin
  family: Gravell
- given: Iman
  family: Shames
- given: Tyler
  family: Summers
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/gravell21a/gravell21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
