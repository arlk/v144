---
title: Provably Sample Efficient Reinforcement Learning in Competitive Linear Quadratic
  Systems
abstract: "  We study the infinite-horizon zero-sum linear quadratic (LQ) games, where
  the state transition is linear and the cost function is quadratic in states and
  actions of two players. In particular, we develop an adaptive algorithm that can
  properly trade off between exploration and exploitation of the unknown environment
  in LQ games based on the optimism-in-face-of-uncertainty (OFU) principle. We show
  that (i) the average regret of player $1$ (the min player) can be bounded by $\\widetilde{\\mathcal{O}}(1/\\sqrt{T})$
  against any fixed linear policy of the adversary (player $2$); (ii) the average
  cost of player $1$ also converges to the value of the game at a sublinear  $\\widetilde{\\mathcal{O}}(1/\\sqrt{T})$
  rate if the adversary plays adaptively against player $1$ with the same algorithm,
  i.e., with self-play. To the best of our knowledge, this is the first time that
  a probably sample efficient reinforcement learning algorithm is proposed for zero-sum
  LQ games."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang21a
month: 0
tex_title: Provably Sample Efficient Reinforcement Learning in Competitive Linear
  Quadratic Systems
firstpage: 597
lastpage: 598
page: 597-598
order: 597
cycles: false
bibtex_author: Zhang, Jingwei and Yang, Zhuoran and Zhou, Zhengyuan and Wang, Zhaoran
author:
- given: Jingwei
  family: Zhang
- given: Zhuoran
  family: Yang
- given: Zhengyuan
  family: Zhou
- given: Zhaoran
  family: Wang
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/zhang21a/zhang21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
