---
title: Offline Reinforcement Learning from Images with Latent Space Models
abstract: Offline reinforcement learning (RL) refers to the task of learning policies
  from a static dataset of environment interactions. Offline RL enables extensive
  utilization and re-use of historical datasets, while also alleviating safety concerns
  associated with online exploration, thereby expanding the real-world applicability
  of RL. Most prior work in offline RL has focused on tasks with compact state representations.
  However, the ability to learn directly from rich observation spaces like images
  is critical for real-world applications like robotics. In this work, we build on
  recent advances in model-based algorithms for offline RL, and extend them to high-dimensional
  visual observation spaces. Model-based offline RL algorithms have achieved state
  of the art results in state based tasks and are minimax optimal. However, they rely
  crucially on the ability to quantify uncertainty in the model predictions. This
  is particularly challenging with image observations. To overcome this challenge,
  we propose to learn a latent-state dynamics model, and represent the uncertainty
  in the latent space. Our approach is both tractable in practice and corresponds
  to maximizing a lower bound of the ELBO in the unknown POMDP. Through experiments
  on a range of challenging image-based locomotion and robotic manipulation tasks,
  we find that our algorithm significantly outperforms previous offline model-free
  RL methods as well as state-of-the-art online visual model-based RL methods. Moreover,
  we also find that our approach excels on an image-based drawer closing task on a
  real robot using a pre-existing dataset. All results including videos can be found
  online at \url{https://sites.google.com/view/lompo/}.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rafailov21a
month: 0
tex_title: Offline Reinforcement Learning from Images with Latent Space Models
firstpage: 1154
lastpage: 1168
page: 1154-1168
order: 1154
cycles: false
bibtex_author: Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea
author:
- given: Rafael
  family: Rafailov
- given: Tianhe
  family: Yu
- given: Aravind
  family: Rajeswaran
- given: Chelsea
  family: Finn
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/rafailov21a/rafailov21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
