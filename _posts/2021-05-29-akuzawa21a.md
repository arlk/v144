---
title: Estimating Disentangled Belief about Hidden State and Hidden Task for Meta-Reinforcement
  Learning
abstract: There is considerable interest in designing meta-reinforcement learning
  (meta-RL) algorithms, which enable autonomous agents to adapt new tasks from small
  amount of experience. In meta-RL, the specification (such as reward function) of
  current task is hidden from the agent. In addition, states are hidden within each
  task owing to sensor noise or limitations in realistic environments. Therefore,
  the meta-RL agent faces the challenge of specifying both the hidden task and states
  based on small amount of experience. To address this, we propose estimating disentangled
  belief about task and states, leveraging an inductive bias that the task and states
  can be regarded as global and local features of each task. Specifically, we train
  a hierarchical state-space model (HSSM) parameterized by deep neural networks as
  an environment model, whose global and local latent variables correspond to task
  and states, respectively. Because the HSSM does not allow analytical computation
  of posterior distribution, i.e., belief, we employ amortized inference to approximate
  it. After the belief is obtained, we can augment observations of a model-free policy
  with the belief to efficiently train the policy. Moreover, because task and state
  information are factorized and interpretable, the downstream policy training is
  facilitated compared with the prior methods that did not consider the hierarchical
  nature. Empirical validations on a GridWorld environment confirm that the HSSM can
  separate the hidden task and states information. Then, we compare the meta-RL agent
  with the HSSM to prior meta-RL methods in MuJoCo environments, and confirm that
  our agent requires less training data and reaches higher final performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: akuzawa21a
month: 0
tex_title: Estimating Disentangled Belief about Hidden State and Hidden Task for Meta-Reinforcement
  Learning
firstpage: 73
lastpage: 86
page: 73-86
order: 73
cycles: false
bibtex_author: Akuzawa, Kei and Iwasawa, Yusuke and Matsuo, Yutaka
author:
- given: Kei
  family: Akuzawa
- given: Yusuke
  family: Iwasawa
- given: Yutaka
  family: Matsuo
date: 2021-05-29
address:
container-title: Proceedings of the 3rd Conference on Learning for Dynamics and Control
volume: '144'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 5
  - 29
pdf: http://proceedings.mlr.press/v144/akuzawa21a/akuzawa21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
